{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6XVBXw_VRYd"
      },
      "source": [
        "# Data Cleaning with Pandas: A Beginner's Guide\n",
        "\n",
        "Welcome to this hands-on lab where you'll learn the essential first steps in any data analysis project: loading, exploring, and cleaning data. We'll be using the popular `pandas` library in Python to work with a real-world dataset from the World Bank.\n",
        "\n",
        "**Lab Scenario:**\n",
        "You will take on the role of a data analyst who has just received a new dataset. You will go through the realistic process of:\n",
        "1. Loading the data as-is.\n",
        "2. Discovering problems with the data (like incorrect data types).\n",
        "3. Writing transformations to clean the data.\n",
        "4. Handling missing values.\n",
        "5. Saving your cleaned data for future analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSWUql4_VRYf"
      },
      "source": [
        "## 1. Setting Up Our Environment\n",
        "\n",
        "First, we need to import the `pandas` library. We'll import it and give it the shorter alias `pd`, which is a common convention."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vZbFCiKVRYf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y34xV89jVRYf"
      },
      "source": [
        "## 2. Loading the Data (The First Look)\n",
        "\n",
        "Let's load our dataset. We have a CSV file named `world_bank_data.csv`. We will load it in the most basic way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmjZPwi1VRYf"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('data/world_bank_data.csv')\n",
        "\n",
        "# The 'df' variable now holds our data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can preview the loaded data by executing a code cell with a `df` code/command or by using `head()` or `tail()` function, eg. `df.head()`. Use these 3 commands and observe the difference."
      ],
      "metadata": {
        "id": "eC9QP1rUWBAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code"
      ],
      "metadata": {
        "id": "Q2X0eeINWU4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should observe that bottom (tail) rows contain some metadata and empty rows. By default only 5 rows are displayed for head or tail function. You can modify this behaviour by adding a numeric `n` **function parameter** to these functions. Please display more bottom rows to understand how many bottom rows should be deleted/cut out of `df` data frame.\n",
        "\n",
        "**Tip:** A function parameter usage `some_object.some_function(parameter_name=<parameter_value>)`"
      ],
      "metadata": {
        "id": "o_5hRgpcXKLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code"
      ],
      "metadata": {
        "id": "iDZTqBsFZVvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you know the answer let's figure out how to \"trim\" these unnecesary rows.\n",
        "We can do it by reading the file once again with a `read_csv` function, but this time adding `skipfooter` parameter with a number of rows to skip at the bottom."
      ],
      "metadata": {
        "id": "9ts9Gfr6ZaTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code"
      ],
      "metadata": {
        "id": "0DZI1jp5aoxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kw2zjyxYVRYg"
      },
      "source": [
        "## 3. Observing the Problem\n",
        "\n",
        "Now that the data is loaded, let's inspect it. A good analyst always checks their data types."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwFNPfBqVRYg"
      },
      "source": [
        "### Your Turn!\n",
        "\n",
        "Use the `.info()` method on the DataFrame to see a summary of the data, including the data types of each column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xv3QViu6VRYg"
      },
      "outputs": [],
      "source": [
        "# your code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnCxLLa3VRYg"
      },
      "source": [
        "### Analysis of the Problem\n",
        "\n",
        "Look at the output of `.info()`. Do you see the issue?\n",
        "\n",
        "The columns for the years (e.g., `1990 [YR1990]`, `2000 [YR2000]`, etc.) should be numeric, but pandas has loaded them as `object` type. In pandas, `object` usually means the column contains text (strings).\n",
        "\n",
        "**Why did this happen?**\n",
        "This happens when a column contains a mix of numbers and non-numeric characters. If even one value in a column is not a number, pandas will play it safe and treat the entire column as text. In our case, the dataset uses `..` to represent missing data, and these double dots are not numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Wjoviu1VRYg"
      },
      "source": [
        "## 4. Transforming the Data\n",
        "\n",
        "Now we will fix the data types step by step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MGUL4GlVRYg"
      },
      "source": [
        "### Step 1: Understanding Column Modification\n",
        "\n",
        "Let's start by fixing just one column. We'll use the '2022 [YR2022]' column as an example.\n",
        "To convert string values to numbers, pandas provides the `pd.to_numeric` function."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's look at the first few values of our column before conversion\n",
        "print(\"Before conversion:\")\n",
        "print(df['2022 [YR2022]'].head())\n",
        "\n",
        "# Convert the column to numeric\n",
        "df['2022 [YR2022]'] = pd.to_numeric(df['2022 [YR2022]'], errors='coerce')\n",
        "\n",
        "# Look at the values after conversion\n",
        "print(\"\\nAfter conversion:\")\n",
        "print(df['2022 [YR2022]'].head())\n",
        "\n",
        "# Check the dataframe info to see the type change\n",
        "df.info()"
      ],
      "metadata": {
        "id": "verbYs93mwXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `errors='coerce'` parameter tells pandas:\n",
        "- Try to convert each value to a number\n",
        "- If a value can't be converted (like our '..' strings), replace it with `NaN` (Not a Number)\n",
        "- `NaN` is how pandas represents missing numeric data"
      ],
      "metadata": {
        "id": "LOwW24M7nYxl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Your turn**\n",
        "Convert another numeric column yourself, eg. 1990. Please note how many null values are there."
      ],
      "metadata": {
        "id": "5R72UCOInAwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code"
      ],
      "metadata": {
        "id": "C657Vm1unRtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Working with Column Names\n",
        "\n",
        "Before we fix all columns, let's learn how to work with column names.\n",
        "The `df.columns` gives us access to all column names in our DataFrame.\n",
        "\n",
        "#### Part A: Listing Column Names\n",
        "First, let's see all our column names:"
      ],
      "metadata": {
        "id": "1YPdyku0nlJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's print all column names using a for loop\n",
        "print(\"Columns in our DataFrame:\")\n",
        "for column_name in df.columns:\n",
        "    print(column_name)"
      ],
      "metadata": {
        "id": "CJYl8epvm8Qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Part B: Filtering Columns\n",
        "Sometimes we want to process only certain columns. We can use if/else statements to decide which columns to work with.\n",
        "\n",
        "Let's create a simple example that identifies which columns are year columns and which are not:"
      ],
      "metadata": {
        "id": "JxAgM2pQn9hn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define which columns we want to ignore\n",
        "columns_to_ignore = ['Series Name', 'Series Code', 'Country Name', 'Country Code']\n",
        "\n",
        "# Loop through columns and check each one\n",
        "print(\"\\nChecking each column:\")\n",
        "for column_name in df.columns:\n",
        "    if column_name in columns_to_ignore:\n",
        "        print(f\"{column_name}: This is a text column - skip conversion\")\n",
        "    else:\n",
        "        print(f\"{column_name}: This is a numeric column - should convert\")\n",
        "\n",
        "# We can also count how many columns of each type we have\n",
        "numeric_columns = df.columns.difference(columns_to_ignore)\n",
        "print(f\"\\nSummary:\")\n",
        "print(f\"Text columns: {len(columns_to_ignore)}\")\n",
        "print(f\"Numeric columns: {len(numeric_columns)}\")"
      ],
      "metadata": {
        "id": "qGbjphaFnuwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This helps us understand:\n",
        "1. How to check if a column is in a list using `in`\n",
        "2. How to use if/else to make decisions about each column\n",
        "3. How many columns we'll need to convert to numeric type"
      ],
      "metadata": {
        "id": "8T9MsOywoGe7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Fixing All Numeric Columns\n",
        "\n",
        "Now that we know how to:\n",
        "1. Convert a single column to numeric type\n",
        "2. Loop through column names\n",
        "\n",
        "We can combine these to fix all numeric columns at once. We'll need to skip the columns that should remain as text (like 'Country Name').\n",
        "\n",
        "Here's what we'll do:\n",
        "1. Define which columns should NOT be converted to numbers\n",
        "2. Loop through all columns\n",
        "3. Convert appropriate columns to numeric type"
      ],
      "metadata": {
        "id": "u9h76gteoLZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the columns that should remain as text\n",
        "\n",
        "\n",
        "# Loop through all columns in the DataFrame\n",
        "    # Check if the column is NOT in our list of non-numeric columns\n",
        "        # Convert the column to numeric, coercing errors to NaN\n",
        "\n",
        "# Now, let's check the .info() again to see if our conversion worked!"
      ],
      "metadata": {
        "id": "Rl05cZvDoPDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxuTyzRjVRYg"
      },
      "source": [
        "## 5. Handling Missing Values\n",
        "\n",
        "Now that our data types are correct and our non-numeric values have been converted to `NaN`, we can properly handle the missing data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o24sGBlVRYh"
      },
      "source": [
        "### Why do we replace missing values?\n",
        "\n",
        "Many mathematical operations (like calculating a mean or sum) will fail or produce incorrect results if missing values are present. Depending on the goal, we can either drop rows with missing data or fill them in with a reasonable substitute.\n",
        "\n",
        "- **Mean:** A good choice when the data is fairly symmetrical and doesn't have extreme outliers.\n",
        "- **Median:** A better choice when the data has outliers, as the median is less sensitive to extreme values.\n",
        "- **Mode:** Used for categorical (text-based) data to fill in with the most frequent value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0R_W1ywjVRYh"
      },
      "source": [
        "### Your Turn!\n",
        "\n",
        "First, get a count of missing values in each column using `.isnull().sum()` to see the extent of the problem. Please use the knowledge from previous section and use `for loop` to print null counts for each column.\n",
        "\n",
        "**Tip:** Example for single a column\n",
        "\n",
        "```python\n",
        "print(f\"Missing values in 2022 column before filling: {df['2022 [YR2022]'].isnull().sum()}\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UR7pU2aZVRYh"
      },
      "outputs": [],
      "source": [
        "# your code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK-LLDO8VRYh"
      },
      "source": [
        "Let's practice by filling the missing values in the `2022 [YR2022]` column with the *median* of that column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4f16PlL1VRYh"
      },
      "outputs": [],
      "source": [
        "# your code\n",
        "# 1. Calculate the median of the '2022 [YR2022]' column\n",
        "median_val = df['2022 [YR2022]'].median()\n",
        "\n",
        "# 2. Use .fillna() on specific column (df[<column_name>].fillna()) to replace the missing values with the median.\n",
        "#    Use inplace=True to modify the DataFrame directly.\n",
        "\n",
        "\n",
        "# 3. Verify that the missing values in the column are filled\n",
        "print(f\"Missing values in 2022 column after filling: {df['2022 [YR2022]'].isnull().sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now fill missing values for all numeric columns using `for loop`"
      ],
      "metadata": {
        "id": "qRkLdKb-untZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code"
      ],
      "metadata": {
        "id": "Vvda8dnLunL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07yVAXwKVRYh"
      },
      "source": [
        "## 6. Saving the Cleaned Data\n",
        "\n",
        "Once you have cleaned your data, it's a good practice to save the result to a new file. This way, you don't have to repeat the cleaning steps every time you want to perform analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22VPCW5_VRYh"
      },
      "source": [
        "### Your Turn!\n",
        "\n",
        "Use the `.to_csv()` method to save your cleaned DataFrame (`df`) to a new file called `cleaned_world_bank_data.csv` in a data directory.\n",
        "\n",
        "**Hint:** Include the argument `index=False` to prevent pandas from writing the DataFrame index as a new column in your CSV file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7V2ODuELVRYh"
      },
      "outputs": [],
      "source": [
        "# your code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mfNHc8zVRYh"
      },
      "source": [
        "## 7. Congratulations!\n",
        "\n",
        "You've completed this data cleaning lab. You have learned the realistic workflow of a data analyst:\n",
        "- Loading raw data and identifying problems.\n",
        "- Using transformations to fix data types.\n",
        "- Strategically handling missing values.\n",
        "- Saving your clean data for the next stage of analysis.\n",
        "\n",
        "These are fundamental skills that you'll use in every data analysis project. Keep practicing!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}