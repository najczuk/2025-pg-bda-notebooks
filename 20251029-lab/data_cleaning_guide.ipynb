{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning with Pandas: A Beginner's Guide\n",
    "\n",
    "Welcome to this hands-on lab where you'll learn the essential first steps in any data analysis project: loading, exploring, and cleaning data. We'll be using the popular `pandas` library in Python to work with a real-world dataset from the World Bank.\n",
    "\n",
    "**Lab Scenario:**\n",
    "You will take on the role of a data analyst who has just received a new dataset. You will go through the realistic process of:\n",
    "1. Loading the data as-is.\n",
    "2. Discovering problems with the data (like incorrect data types).\n",
    "3. Writing transformations to clean the data.\n",
    "4. Handling missing values.\n",
    "5. Saving your cleaned data for future analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting Up Our Environment\n",
    "\n",
    "First, we need to import the `pandas` library. We'll import it and give it the shorter alias `pd`, which is a common convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the Data (The First Look)\n",
    "\n",
    "Let's load our dataset. We have a CSV file named `world_bank_data.csv`. We will load it in the most basic way. \n",
    "\n",
    "*Note: We are including the `skipfooter=5` and `engine='python'` parameters because there are some informational rows at the very end of the file that are not part of the actual data. This is a common issue in real-world files.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/world_bank_data.csv', skipfooter=5, engine='python')\n",
    "\n",
    "# The 'df' variable now holds our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Observing the Problem\n",
    "\n",
    "Now that the data is loaded, let's inspect it. A good analyst always checks their data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn!\n",
    "\n",
    "Use the `.info()` method on the DataFrame to see a summary of the data, including the data types of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the Problem\n",
    "\n",
    "Look at the output of `.info()`. Do you see the issue? \n",
    "\n",
    "The columns for the years (e.g., `1990 [YR1990]`, `2000 [YR2000]`, etc.) should be numeric, but pandas has loaded them as `object` type. In pandas, `object` usually means the column contains text (strings).\n",
    "\n",
    "**Why did this happen?**\n",
    "This happens when a column contains a mix of numbers and non-numeric characters. If even one value in a column is not a number, pandas will play it safe and treat the entire column as text. In our case, the dataset uses `..` to represent missing data, and these double dots are not numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transforming the Data\n",
    "\n",
    "Now we will fix the data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Convert Numeric Columns to Floats\n",
    "\n",
    "Our goal is to convert all the year columns from `object` to `float` (a float is a number that can have decimals). \n",
    "\n",
    "A robust way to do this is to use the `pd.to_numeric` function. We will apply this to all columns that should be numeric. The key is the `errors='coerce'` argument. This tells pandas: \"Try to convert the values to numbers. If you find a value that you can't convert (like our `..` strings), don't raise an error. Instead, replace that value with `NaN` (Not a Number).\"\n",
    "\n",
    "`NaN` is the standard way pandas represents missing numeric data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn!\n",
    "\n",
    "Complete the code below. We have already identified the list of columns that should *not* be numeric. Your task is to loop through all the columns in the DataFrame (`df.columns`) and if a column is **not** in our `non_numeric_cols` list, apply the `pd.to_numeric` function to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns that should remain as text\n",
    "non_numeric_cols = ['Series Name', 'Series Code', 'Country Name', 'Country Code']\n",
    "\n",
    "# Loop through all columns in the DataFrame\n",
    "for col in df.columns:\n",
    "    # Check if the column is NOT in our list of non-numeric columns\n",
    "    if col not in non_numeric_cols:\n",
    "        # --- YOUR CODE GOES HERE --- #\n",
    "        # Convert the column to numeric, coercing errors to NaN\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        # ------------------------- #\n",
    "\n",
    "# Now, let's check the .info() again to see if our conversion worked!\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Handling Missing Values\n",
    "\n",
    "Now that our data types are correct and our non-numeric values have been converted to `NaN`, we can properly handle the missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do we replace missing values?\n",
    "\n",
    "Many mathematical operations (like calculating a mean or sum) will fail or produce incorrect results if missing values are present. Depending on the goal, we can either drop rows with missing data or fill them in with a reasonable substitute.\n",
    "\n",
    "- **Mean:** A good choice when the data is fairly symmetrical and doesn't have extreme outliers.\n",
    "- **Median:** A better choice when the data has outliers, as the median is less sensitive to extreme values.\n",
    "- **Mode:** Used for categorical (text-based) data to fill in with the most frequent value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn!\n",
    "\n",
    "First, get a count of missing values in each column using `.isnull().sum()` to see the extent of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's practice by filling the missing values in the `2022 [YR2022]` column with the *median* of that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- YOUR CODE GOES HERE --- #\n",
    "# 1. Calculate the median of the '2022 [YR2022]' column\n",
    "\n",
    "\n",
    "# 2. Use .fillna() to replace the missing values with the median. \n",
    "#    Use inplace=True to modify the DataFrame directly.\n",
    "\n",
    "\n",
    "# ------------------------- #\n",
    "\n",
    "# Verify that the missing values in the column are filled\n",
    "print(f\"Missing values in 2022 column after filling: {df['2022 [YR2022]'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saving the Cleaned Data\n",
    "\n",
    "Once you have cleaned your data, it's a good practice to save the result to a new file. This way, you don't have to repeat the cleaning steps every time you want to perform analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn!\n",
    "\n",
    "Use the `.to_csv()` method to save your cleaned DataFrame (`df`) to a new file called `cleaned_world_bank_data.csv`.\n",
    "\n",
    "**Hint:** Include the argument `index=False` to prevent pandas from writing the DataFrame index as a new column in your CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- YOUR CODE GOES HERE --- #\n",
    "\n",
    "\n",
    "# ------------------------- #\n",
    "\n",
    "print(\"Cleaned data saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Congratulations!\n",
    "\n",
    "You've completed this data cleaning lab. You have learned the realistic workflow of a data analyst:\n",
    "- Loading raw data and identifying problems.\n",
    "- Using transformations to fix data types.\n",
    "- Strategically handling missing values.\n",
    "- Saving your clean data for the next stage of analysis.\n",
    "\n",
    "These are fundamental skills that you'll use in every data analysis project. Keep practicing!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}